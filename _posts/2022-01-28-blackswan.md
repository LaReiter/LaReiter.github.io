---
title: "Black swans"
mathjax: true
layout: post
categories: media
---

![Black Swan](/assets/black swan.jpg)

## Induction
A way to understand the concept of induction, is through the popular example with swans. 

At some point in time, the belief in Europe was that no such thing as a black swan existed. 
You could observe a white swan, then a 2nd white swan, a 3rd white swan and inductively you concluded that all swans must be white.
Eventually, as the Europeans travelled east, the next swan in the line of observed swans, turned out to be black. So much for induction. 

In fact, the induction principle is something which is at the center of human perception. 
Through our entire life span, we are continuously strengthening or diminishing certain beliefs, based on induction. 
When we observe certain ‘things’ enough times, we slowly accept them as truth. At the top of it all, is the mother of all implicit truths, namely that nature is uniform. 
The laws of physics are not bend or changed. And every natural mechanism behaves the same, independent of the past.

## Black swan events and machine learning
Whenever something ‘turn out’ to be radically different than we expected, we talk about a black swan event.   

In the example with the actual black swan, the knowledge was shared over Europe, and the theory books was updated. 
The impact was not critical, in the sense that the presumed (incorrect) wisdom of only white swans only limited our understanding of the bird.

On the other hand, imagine that the year is 2050, and we are sitting comfortable in our self-driven Future AI-X Gesla. This is a car that has gone through immense (machine learning) training, to optimize decisions, and increase safety measures. It’s a car trained with state-of-the art AI technology, and it’s a car that is completely safe. 
But what happens, if on the road, the Gesla now is faced with a black swan event. 

One would argue, that any complex AI is robust to changes in the environment. But a black swan event, is not a subtle change. It is a drastically new setting.
By the very definition of a black swan event, they are seldom and also extreme. And we should remember, that the data fed into any machine, might not capture these drastic events. Or even worse, mark them as ‘outliers’.

## Leap of faith
So at the end of the day, we are faced with the question, of how much we can trust technology designed on the basis of ‘some’ data. 
A common saying is, that the machine (program) is no better than the data used to build it. 

We human make inductive reasoning all the time, but unlike the human, a machine can (probably not) adapt to extreme changes in the setting using any traditional learning paradigm. 

Once again, I raise the the following question: If machines, and so-called AIs, are to perform complex tasks in the future, we are forced to make machines, which goes beyond simple pattern recognition, and instead crunch data in new uncharted ways. We need to make models which understand both the causal and erratic order of the world, as we humans do, and are not operating within some narrow probability-based scheme.  
